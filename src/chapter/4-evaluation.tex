\chapter{Evaluation}\label{ch:evaluation}

Die in Kapitel~\ref{ch:implementation} entstandene Software wurde im Verlauf dieser Arbeit einer umfangreichen Evaluierungsphase unterzogen.
Dadurch konnten individuelle Abläufe ermöglicht, unvorhergesehene Benutzerinteraktionen erfasst und ergonomische Bedienbarkeit sichergestellt werden.
In diesem Kapitel werden drei Anwendungsfälle betrachtet, in denen die Werkzeuge fulib.org und fulibFeedback verwendet wurden.
Dabei handelt es sich um drei Veranstaltungen der Universität Kassel aus dem Sommer- bis Wintersemester 2021 bis 2022.
In Abschnitt~\ref{sec:pm-2021-2022} wird zunächst die Veranstaltung \ac{pm}\footnote{
    Fachgebiet Softwaretechnik, Prof.\ Dr.\ Albert Zündorf.
} des Wintersemesters 2021/22 betrachtet.
Die Abschnitte~\ref{sec:algods-2021} und~\ref{sec:einfinf-2021-2022} bieten daraufhin Einblicke in die Veranstaltungen "Algorithmen und Datenstrukturen"\footnote{
    Fachgebiet Programmiersprachen/-Methodik, Prof.\ Dr.\ Claudia Fohry.\label{fn:fg-plm}
} im Sommersemester 2021 und "Einführung in die Informatik"\footref{fn:fg-plm} im Wintersemester 2021/22.

\todo{
    Referenzen:
    Eingewöhnungszeit~\ref{subsec:grading}.
    Statistiken~\ref{subsec:statistics}: Relative Anteile Code Search/Manuell, Code Search Savings, Punktzahl vs Bewertungsanzahl.
    fulibFeedback: Wahl von Codeabschnitten~\ref{subsec:choosing-code-snippets}.
}

\section{\acl{pm}}\label{sec:pm-2021-2022}

Die Veranstaltung \ac{pm} stellt die größten Teil der Evaluation dar.
Sie umfasste ingesamt \todo{zwölf} Aufgabenblättern, welche von bis zu 125 Studierenden bearbeitet und bis zu sechs Personen mit fulib.org und fulibFeedback bewertet wurden.
Dabei sind individuelle Anmerkungen sowie eine große Anzahl von Metriken in Form der Statistik entstanden.
In diesem Abschnitt werden einige Ansichten der Benutzer erläutert (Abschnitt~\ref{subsec:user-feedback}) und die Rohdaten der Statistik erfasst (Abschnitt~\ref{subsec:pm-statistics}).
Des Weiteren wird erläutert, welche Erfahrung mit den Werkzeugen zu Anpassungen der Aufgabenstellungen und Bewertungskriterien geführt haben, um den Ablauf der Bewertung zu optimieren (Abschnitt~\ref{subsec:pm-adaptations}).

\subsection{Benutzer-Anmerkungen}\label{subsec:user-feedback}

Während der Testphase der Werkzeuge in \ac{pm} wurden die Bewertenden gebeten, nach jeder Hausaufgabe eine kurze Rückmeldung zu geben.
Diese konnte generelle Bemerkungen, Anfragen für neue Features, Verbesserungsvorschläge und kurze Fehlerberichte beeinhalten.
Alle Rückmeldungen wurden in einem öffentlichen Issue\footnote{
    \url{https://github.com/fujaba/fulib.org/issues/196}
} auf GitHub gesammelt.
Nachfolgend werden einige der wichtigsten Erkenntnisse daraus beschrieben, da sie maßgeblich zu der Entwicklung von fulib.org und fulibFeedback beigetragen haben.

\subsubsection{Auswahl von Codeabschnitten}

Die wichtigste Erkenntnis aus den Benutzeranmerkungen war die Art und Weise, wie Codeabschnitte ausgewählt werden.
Der Ablauf, der in Abschnitt~\ref{subsec:choosing-code-snippets} beschrieben wurde und beide Werkzeuge symbiotisch kombiniert, wurde erst in einer späteren Version von fulibFeedback eingeführt.
Zuvor wurde die gesamte Bewertung von Code allein mit fulibFeedback gemacht.
Mittels Code Actions des \ac{lsp} wurde ein Menü angezeigt, das alle Teilaufgaben baumförmig anzeigte.
Die Aktivierung eines Menüeintrags hat dazu geführt, das über dem ausgewählten Quellcode ein Kommentar eingefügt wurde, in dem Punktzahl und Remark eingegeben werden konnten.
In diesem Kommentar konnten zwei Code Actions verwendet werden, um die Bewertung zu erstellen.
Diese Vorgehensweise hatte einige erheblich Nachteile:

\begin{itemize}
    \item Das Menü, das die Teilaufgaben anzeigte, konnte bei einer großen Anzahl von Teilaufgaben unübersichtlich werden und teilweise die Bildschirmhöhe überschreiten.
    Dies hat insbesondere die Effizienz eingeschränkt, da einige Zeit zum Suchen der nächsten unbewerteten Teilaufgabe notwendig war.
    \item Der automatisch erstellte Kommentar enthielt nur die \ac{id} der zuvor ausgewählten Teilaufgaben, aber nicht deren Beschreibung.
    Es kam vor, dass Bewertende versehentlich die falsche Teilaufgabe auswählten und dies nicht bermerkten, bevor die Bewertung erstellt wurde.
    \item Generell erforderte der automatisch erstellte Kommentar einen erheblichen Programmieraufwand seitens des Language Servers.
    Dies ist der Einschränkung des \ac{lsp} verschuldet, keine Möglichkeit zu bieten, als Teil einer Code Action den Benutzer des Editors nach einer Eingabe zu Frage.
    Wäre dies möglich, hätten Remark und Punktzahl beispielweise über ein Prompt-Dialog erfragt werden können.
    Die hinzugefügten Kommentarzeilen erwiesen sich besonders als Problem, indem sie die darunterliegenden Zeilennummern verschoben, obwohl diese für die Hinterlegung von Codeabschnitten und für die Anzeige des Feedbacks auf GitHub relevant sind.
    \item Der Ablauf erlaubte nicht die Auswahl mehrere Codeabschnitte als Teil einer Bewertung in einem Schritt.
    Es war notwendig, zuerst einen Abschnitt auszuwählen, eine Bewertung zu erstellen, einen weiteren Abschnitt auszuwählen, und zuletzt die Bewertung zu bearbeiten.
    Dies erforderte erheblichen Aufwand bei der korrekten Implementierung von Code Search.
    Bewertungen von anderen Lösungen, die anhand des ersten Codeabschnitts automatisch erstellt wurden, mussten wieder angepasst oder \ac{ggf} gelöscht werden, falls der zweite Codeabschnitt in der Lösung nicht gefunden wurde.
    Damit verbundene Probleme haben sich besonders in Hausaufgabe 3 von \ac{pm} manifestiert.
\end{itemize}

Generell erwies sich diese Art der Bewertung als sehr umständlich für die Bewertenden.
Die Einführung des neuen Ablaufs aus Abschnitt~\ref{subsec:choosing-code-snippets} konnte die Implementierung der fulibFeedback-Erweiterung deutlich vereinfachen, ermöglichte neue Verbesserungen und Hilfestellungen in der fulib.org-Oberfläche und wurde von den Benutzern positiv empfangen.

\subsubsection{Benutzerfehler mit Code Search}

\todo{
    Gefahren von unüberlegter Auswahl mit Code Search~\ref{subsec:choosing-code-snippets}.
}

\subsubsection{Sonstige \acl{qol}-Verbesserungen}

\todo{
    Kleine Oberflächenelemente als Resultat von Benutzerfeedback, zB im Evaluation-Modalfenster:
    Punkte-Shortcut-Buttons, Remark ausklappen, Task-Description im Header, Code Search Preview.
    VSCode Alternativen, Git Clone Protokoll, Firefox/andere Browser.
}

\subsubsection{Statistiken}\label{subsec:pm-statistics}

\todo{
    Vergleich aller Hausaufgaben.
    Wichtigste Metriken: Anteil Code Search, Zeit bewertet, Zeit gespart.
    Besonderheiten bei Tasks.
}

\subsection{Anpassungen}\label{subsec:pm-adaptations}

\todo{
    Vorgaben für Namen, fx:ids.
    Beobachtungen bei Aufgabenstellung allgemein (Beispiel Todos -> mehr identische Strukturen, bessere Code Search Ergebnisse).
}

\todo{
    Erfahrungsbericht, User Feedback.
}

\section{Algorithmen und Datenstrukturen}\label{sec:algods-2021}

\todo{
    Keine Bewerter, nur Betrachten der Daten.
    Statistiken.
}

\section{Einführung in die Informatik}\label{sec:einfinf-2021-2022}

\todo{
    Erfahrungsbericht, User Feedback.
}
