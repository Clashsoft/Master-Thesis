\chapter{Auswertung}\label{ch:results}

Die Evaluation hat eine Vielzahl von Erkenntnissen und Daten geliefert, die nun ausgewertet werden.
Dabei wird zunächst auf die Zielsetzung aus Abschnitt~\ref{sec:goals} Bezug genommen.
Weiterhin werden die Forschungsergebnisse präsentiert, die Antworten auf die Forschungsfragen aus Abschnitt~\ref{sec:research-questions} liefern.

\section{Zielerfüllung}\label{sec:goals-reached}

Zu Beginn wurden einige Anforderungen und Rahmenbedingungen gestellt, welche die Software erfüllen sollte, die für diese Arbeit entwickelt wurde.
Zunächst sollte sie eine unterstützende Funktion bei der Bewertung von Abgaben erfüllen.
Dies wurde ermöglicht, indem Lösungen automatisch importiert werden, die auf Knopfdruck im Editor geöffnet werden können, und Bewertungen angelegt werden können.
Vorherige Abläufe wie das manuelle Clonen von GitHub, Zusammenstellen von Feedback und Berechnung von Punkten wurden dadurch ersetzt.
Es ist möglich, Aufgaben bis auf einzelne Punkte zu definieren und dadurch detaillierte Statistiken über Erfolge bei kleinen Schritten zu ermitteln.
Mehrere Abgaben können durch Code Search gleichzeitig bewertet werden, wodurch wertvolle Bewertungszeit gespart wird.
Die Übertragung von Bewertungen auf anderen Lösungen erfolgt sofort, sodass betroffene Bewertende keine vermeidbare Arbeit beginnen müssen.

Die Verwendung der Werkzeuge ist gänzlich optional, sowohl für Studierende als auch Bewertende.
Bestehende Abgabemechanismen wie GitHub Classroom bleiben erhalten und auch Feedback kann weiterhin mit Issues oder anderen Mitteln eingereicht werden.
Die Software unterstützt ferner den Import von Lösungen beliebiger Abgabesysteme in Form von Dateien sowie das Versenden von Feedback via Email oder Text.
Damit wird die Integration beliebiger Plattformen ermöglicht.
Bewertende, welche die Werkzeuge nicht verwenden möchten, können weiterhin auf bewährte Methoden zurückgreifen.
Sie verzichten dabei jedoch auf die Vorteile von Code Search und sonstiger gesteigerter Produktivität.

\section{Forschungsergebnisse}\label{sec:research-results}

Nachfolgend wir abschließend auf die vier Forschungsfragen eingegangen, die dank der umfangreichen Evaluation beantwortet werden konnten.

Die erste Frage beschäftigte sich damit, ob die Bewertung von Programmieraufgaben automatisiert werden kann.
Die Verwendung von Code Search hat ergeben, dass dies eindeutig möglich ist, wenn auch mit unterschiedlich guten Ergebnissen abhängig von der Aufgabenstellung.
An dieser Stelle sollte auch beachtet werden, dass die Arbeit sich nur auf Aufgaben spezialisiert hat, bei denen auch Programmcode geschrieben wird.
Die Quellcode-Suche wäre bei geeignetem Dateiformat, beispielsweise Textdateien, für andere Aufgaben einsetzbar.
Natürliche Sprache bietet jedoch wesentlich mehr Variationen in der Ausdrucksweise, als es bei Programmiersprachen der Fall ist.
Dies würde die Anwendbarkeit von Code Search erheblich einschränken.
Es ist sogar naheliegend, dass das Finden von ähnlichem Text eher auf ein Plagiat hindeutet.
Bei Veranstaltungen, deren Aufgaben hauptsächlich Quellcode erwarten, lohnt sich dennoch die Einrichtung der Werkzeuge, auch wenn einige Aufgaben in anderer Form gelöst werden.
Die Hausaufgaben 1, 2 und 5 der Veranstaltung "Programmieren und Modellieren" haben dies gezeigt.

In der zweiten Frage sollte ergründet werden, welcher Mehraufwand notwendig ist, um von der automatischen Bewertung zu profitieren.
Mit fulib.org ist lediglich die Einrichtung eines Assignments erforderlich, wie in Abschnitt~\ref{subsec:creating-assignments} beschrieben wurde.
Dies ist in wenigen Minuten möglich, sofern die Liste von Teilaufgaben bereits vorliegt.
Um den Prozess zu beschleunigen, wurde das Markdown-Format als Eingabemöglichkeit hinzugefügt, wodurch mit wenigen Anpassungen der gesamte Baum von Teilaufgaben hinterlegt werden kann.
Nach Anlegen des Assignments sind keine größeren Schritte mehr notwendig.
Bewertende können mit wenigen Klicks die notwendigen Einstellungen tätigen und der Ablauf der Bewertung kann in kurze Zeit erklärt werden.
Es ist nicht erforderlich, eine Musterlösung bereitzustellen, da diese Rolle von der ersten richtigen Lösung eines Studierenden erfüllt wird.
Die Suche von Quellcode benötigt keine Einrichtung eines Compilers, da sie rein textueller Natur ist.
Auch die Bereitstellung von Tests ist nicht notwendig, sofern diese Teil der Aufgabenstellung sind oder am Code erkannt werden kann, ob dieser richtig ist.

\todo{
    Bezugnahme/Wiederholung von~\ref{sec:research-questions}.
    Auswertung der Statistiken der Code Search-Effektivität in Bezug auf Aufgabentypen, Studentenanzahl und Modul.
}
